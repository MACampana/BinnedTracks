{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df31e4c-9306-4190-b000-c1c010cbab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import iminuit\n",
    "import healpy as hp\n",
    "import histlite as hl\n",
    "import csky as cy\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ce727-a5c2-46eb-b21b-70f13ff7e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinnedTemplateAllSky:\n",
    "    \"\"\"For conducting binned calculations using maximum likelihood statistical methods. \n",
    "    For binned sky map of IceCube event data. No separation of likelihood across declinations.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, sig, grl, is_binned=False, savedir=None, name='AllSkyBinnedTemplateAnalysis', \n",
    "                 template=None, gamma=2.7, cutoff=None, \n",
    "                 nside=128, min_dec_deg=-80, max_dec_deg=80, \n",
    "                 verbose=False):\n",
    "        \"\"\"BinnedTemplateAllSky constructor\n",
    "        \n",
    "        Args:\n",
    "            data: Path to numpy array(s) (directory or single file) containing  dtype=[('run', '<i8'), \n",
    "                                                 ('event', '<i8'),\n",
    "                                                 ('subevent', '<i8'),\n",
    "                                                 ('ra', '<f8'),\n",
    "                                                 ('dec', '<f8'),\n",
    "                                                 ('azi', '<f8'),\n",
    "                                                 ('zen', '<f8'),\n",
    "                                                 ('time', '<f8'),\n",
    "                                                 ('logE', '<f8'),\n",
    "                                                 ##('angErr', '<f8')])\n",
    "                                                 \n",
    "                OR: Path to numpy array of binned data (in this case, set is_binned=True)\n",
    "                                     \n",
    "            sig: Path to numpy array containing  dtype = [('run', int), \n",
    "                                                 ('event', int), \n",
    "                                                 ('subevent', int),\n",
    "                                                 ('ra', float), \n",
    "                                                 ('dec', float),\n",
    "                                                 ('true_ra', float), \n",
    "                                                 ('true_dec', float),\n",
    "                                                 ('azi', float), \n",
    "                                                 ('zen', float), \n",
    "                                                 ('time', float),\n",
    "                                                 ('logE', float), \n",
    "                                                 ('true_angErr', float), \n",
    "                                                 ('oneweight', float),     \n",
    "                                                 ('true_energy', float)]\n",
    "            \n",
    "            grl: Path to numpy array with GRL runs\n",
    "                                     \n",
    "            is_binned: boolean, True if argument data is an array of binned_data, otherwise False (data will be binned)\n",
    "            \n",
    "            savedir: path to directory to save binned data. Default: None (don't save)\n",
    "            \n",
    "            name: unique name to identify analysis (used in file names when saving)\n",
    "            \n",
    "            template: path to template object/array or None\n",
    "                TO DO:\n",
    "                    * Rescale template nside for differing energy ranges\n",
    "                                                            \n",
    "            gamma: spectral index for detector acceptance and injections. \n",
    "                  #This should match the one used to create\n",
    "                  #the template if using one saved by csky. \n",
    "                    \n",
    "            cutoff: minimum template value to be considered an On bin\n",
    "                TO DO (???):\n",
    "                    * Implementation without need for cutoff???\n",
    "\n",
    "            nside: integer for healpy nside (Default: 128)\n",
    "                TO DO: \n",
    "                    * Allow nside to differ for different energy ranges\n",
    "                        \n",
    "            min_/max_dec_deg: min and max declination in degrees for likelihood calculations.\n",
    "            \n",
    "            verbose: True for lots of output (Default: False)\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        if template is None:\n",
    "            raise NotImplementedError('Current implementation can only perform template analysis!')\n",
    "        elif cutoff is None:\n",
    "            raise NotImplementedError('Current implementation requires a cutoff to define on/off bins!')\n",
    "        \n",
    "        print('Setting up:')\n",
    "        \n",
    "        self.name = name\n",
    "        self.savedir = savedir\n",
    "        cy.utils.ensure_dir(savedir)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.cutoff = cutoff\n",
    "        self.nside = nside\n",
    "        self.min_dec_deg = min_dec_deg\n",
    "        self.max_dec_deg = max_dec_deg\n",
    "        \n",
    "        self.bin_thetas, self.bin_phis = hp.pix2ang(self.nside, np.arange(hp.nside2npix(self.nside))) \n",
    "        self.bin_ras = self.bin_phis\n",
    "        self.bin_decs = np.pi/2.0 - self.bin_thetas\n",
    "        \n",
    "        self.grl = np.load(grl)\n",
    "        \n",
    "        if is_binned:\n",
    "            self.binned_data = np.load(data)\n",
    "            print(f'Load binned data <-- {data}')\n",
    "            print(f'    Binned data loaded: Contains {len(self.binned_data)} bins with {np.sum(self.binned_data)} counts')\n",
    "            if len(self.binned_data) != hp.nside2npix(self.nside):\n",
    "                raise ValueError(f\"Nside of loaded binned data is {hp.npix2nside(len(self.binned_data))}, but given nside is {self.nside}! You need to rebin your data.\")\n",
    "                \n",
    "        else:\n",
    "            self.load(data)\n",
    "        \n",
    "        self.sig_evs = np.load(sig)\n",
    "        print(f'Load signal array <-- {sig}')        \n",
    "        weights = self.sig_evs['oneweight'] * self.sig_evs['true_energy']**(-self.gamma)\n",
    "        smooth_sig = self.weighted_quantile(self.sig_evs['true_angErr'], weights, 0.5)\n",
    "        print(f'    Median true angular error: {smooth_sig}')\n",
    "        \n",
    "        print(f'Load template <-- {template}')\n",
    "        template = np.load(template, allow_pickle=True)\n",
    "        \n",
    "        \n",
    "        if template.dtype == 'O':\n",
    "            self.template = template.item()['template']\n",
    "            if len(self.template) != hp.nside2npix(self.nside):\n",
    "                print(f'Template nside does not match nside argument:')\n",
    "                print(f'    Template: {hp.npix2nside(len(self.template))} --> Argument: {self.nside}')\n",
    "                print('Adjusting resolution of template and making smoothed PDF... \\n')\n",
    "                \n",
    "                self.template = hp.ud_grade(self.template, self.nside)\n",
    "                self.create_template_pdf(smooth_sig)\n",
    "                \n",
    "            else:\n",
    "                sigmas = np.radians(template.item()['sigmas_deg'])\n",
    "                mindex = (np.abs(sigmas-np.degrees(smooth_sig))).argmin()\n",
    "                self.template_pdf = template.item()['pdf_space_sig'][mindex]            \n",
    "            \n",
    "        else:\n",
    "            self.template = template.copy()\n",
    "            \n",
    "            if len(self.template) != hp.nside2npix(self.nside):\n",
    "                print(f'Template nside does not match nside argument:')\n",
    "                print(f'    Template: {hp.npix2nside(len(self.template))} --> Argument: {self.nside}')\n",
    "                print('Adjusting resolution of template and making smoothed PDF... \\n')\n",
    "\n",
    "                self.template = hp.ud_grade(self.template, self.nside)\n",
    "                self.create_template_pdf(smooth_sig)\n",
    "                \n",
    "            else:\n",
    "                self.create_template_pdf(smooth_sig)\n",
    "            \n",
    "        assert self.template.shape == self.template_pdf.shape, 'Template and template PDF shapes do not match...hmmm'\n",
    "        assert len(self.template) == hp.nside2npix(self.nside), 'Number of bins in template does not match provided nside?!'\n",
    "        assert len(self.template) == len(self.binned_data), 'Number of bins in template does not match number of bins in binned data!'\n",
    "        \n",
    "        self.get_pdfs()\n",
    "\n",
    "        print('***Setup complete!*** \\n')\n",
    "        \n",
    "    def weighted_quantile(self, data, weights, quantile):\n",
    "            ix = np.argsort(data)\n",
    "            data = data[ix] # sort data\n",
    "            weights = weights[ix] # sort weights\n",
    "            csw = np.cumsum(weights)\n",
    "            cut = np.sum(weights) * quantile\n",
    "            if len(data) == 0:\n",
    "                q = 0.0\n",
    "            else:\n",
    "                q = data[csw >= cut][0]\n",
    "            return q\n",
    "        \n",
    "    def bin_data(self, data, verbose=None):#, truth=False, seed=None):\n",
    "        \"\"\"\n",
    "        Convert event data into bin counts using healpy. \n",
    "        \n",
    "        Args:\n",
    "            data: data event array(s)\n",
    "            \n",
    "            verbose: True to show more output (Defaults to class's initited value)\n",
    "            \n",
    "        #    truth: Whether to use true event locations (True), or scramble in right ascension (False)\n",
    "        #\n",
    "        #    seed: integer, Seed for numpy.random.default_rng() used to scramble events (Default: None, meaning unpredictable)\n",
    "        \"\"\"\n",
    "        \n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "            \n",
    "        event_decs = data['dec']\n",
    "        event_ras = data['ra']\n",
    "        #if truth:\n",
    "        #    event_ras = self.data['ra']\n",
    "        #else:            \n",
    "        #    rng_scramble = np.random.default_rng(seed=seed)                \n",
    "        #    event_ras = 2.0 * np.pi * rng_scramble.random(size=len(self.data['ra']))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Binning {len(event_ras)} events with nside={self.nside}...that is {hp.nside2npix(self.nside)} bins! Wow!', end=' ')\n",
    "        \n",
    "        event_pix_nums = hp.ang2pix(self.nside, np.pi/2.0 - event_decs, event_ras)\n",
    "        \n",
    "        if verbose:\n",
    "            print('--> Binning Done.')\n",
    "\n",
    "        return np.bincount(event_pix_nums)\n",
    "    \n",
    "    def load(self, path, verbose=None):\n",
    "        \"\"\"\n",
    "        Loads data and bins it.\n",
    "        \n",
    "        Args:\n",
    "            path: path to directory containing data files or path to a data file\n",
    "            \n",
    "            verbose: True to show more output (Defaults to class's initited value)\n",
    "            \n",
    "        \"\"\"\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "        assert (os.path.isdir(path) or os.path.isfile(path)), f\"Expected path to directory or file, got: {path}\"\n",
    "        \n",
    "        print(f'Loading and binning data from {path}')\n",
    "        if os.path.isdir(path):\n",
    "            files_like = path+'/*.npy'\n",
    "            file_list = sorted(glob(files_like))\n",
    "            binned_data = np.zeros(hp.nside2npix(self.nside))\n",
    "            for file in file_list:\n",
    "                data = np.load(file)\n",
    "                mask = np.isin(data['run'], self.grl)\n",
    "                data = data[mask]\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f'    {file} | ', end=' ')\n",
    "                binned_data = binned_data + self.bin_data(data)\n",
    "            \n",
    "            self.binned_data = binned_data\n",
    "        \n",
    "        else:\n",
    "            data = np.load(path)\n",
    "            mask = np.isin(data['run'], self.grl)\n",
    "            data = data[mask]\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'    {path} | ', end=' ')\n",
    "            self.binned_data = self.bin_data(data)\n",
    "            \n",
    "        del data\n",
    "        gc.collect()\n",
    "        print('--> Data Loading Done. \\n')\n",
    "        \n",
    "        if self.savedir is not None:\n",
    "            savefile = f'{self.savedir}/{self.name}.binned_data.npy'\n",
    "            np.save(savefile, self.binned_data)\n",
    "            print(f'Binned data saved to --> {savefile}')\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def create_bg_acc_spline(self, skw={}):\n",
    "        \"\"\"\n",
    "        Create detector acceptance spline (*background*, sinDec-dependent) for weighted product of likelihoods across declinations.\n",
    "        \n",
    "        Pieces taken from csky.\n",
    "        \n",
    "        TO DO: Is this right?\n",
    "        \n",
    "        Args:          \n",
    "            skw: histlite.Hist.spline_fit kwargs\n",
    "        \n",
    "        Returns: histlite spline object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #BG pdf using only \"off\" pixels as defined by cutoff and within dec bounds\n",
    "        #dec_mask = (self.bin_decs <= np.radians(self.max_dec_deg)) & (self.bin_decs >= np.radians(self.min_dec_deg))\n",
    "        mask = (self.template_pdf <= self.cutoff)\n",
    "\n",
    "        sindec_bins = np.unique(np.concatenate([\n",
    "                             np.linspace(-1, -0.93, 4 + 1),\n",
    "                             np.linspace(-0.93, -0.3, 10 + 1),\n",
    "                             np.linspace(-0.3, 0.05, 9 + 1),\n",
    "                             np.linspace(0.05, 1, 18 + 1) ]) )\n",
    "\n",
    "        h_counts_nocorr = hl.hist(np.sin(self.bin_decs[mask]), weights=self.binned_data[mask], bins=sindec_bins)\n",
    "\n",
    "        #binds = np.digitize(np.sin(self.bin_decs), sindec_bins)\n",
    "        #bs = np.array([np.sum(mask & (binds==ind)) for ind in range(1, len(sindec_bins))])\n",
    "        \n",
    "        bin_edges = np.arcsin(sindec_bins)\n",
    "        dOmega_corr = []\n",
    "        for i in np.arange(len(bin_edges)-1):\n",
    "            pixels_in_band = hp.query_strip(self.nside, np.pi/2-bin_edges[i+1], np.pi/2-bin_edges[i])\n",
    "            bool_array = np.isin(pixels_in_band, np.arange(hp.nside2npix(self.nside))[~mask])\n",
    "            number_true = np.count_nonzero(bool_array)\n",
    "            corr = float(len(pixels_in_band)/float((len(pixels_in_band)-number_true)))\n",
    "            dOmega_corr.append(corr)\n",
    "        \n",
    "        counts_corr = h_counts_nocorr.values * np.array(dOmega_corr)\n",
    "        \n",
    "        h_counts = hl.Hist(values=counts_corr, bins=sindec_bins)\n",
    "        \n",
    "        h = h_counts.normalize(density=True) / (2*np.pi)\n",
    "\n",
    "        skw = {}\n",
    "        skw.setdefault('s', 0)\n",
    "        skw.setdefault('k', 2)\n",
    "        skw.setdefault('log', True)\n",
    "        s_hl = h.spline_fit(**skw)\n",
    "        \n",
    "        self.bg_acc_spline = s_hl.spline\n",
    "        \n",
    "        return self.bg_acc_spline\n",
    "    \n",
    "    def create_signal_acc_spline(self, skw={}):\n",
    "        \"\"\"\n",
    "        Create detector acceptance spline (*signal*, sinDec-dependent) for weighted product of likelihoods across declinations.\n",
    "        \n",
    "        Pieces taken from csky.\n",
    "        \n",
    "        TO DO: Is this right? Spline could use some work.\n",
    "        \n",
    "        Args:\n",
    "            skw: histlite.Hist.spline_fit kwargs (Unused.)\n",
    "        \n",
    "        Returns: scipy spline object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "        xs = np.r_[self.bin_decs[0], self.bin_decs, self.bin_decs[-1]]\n",
    "        ws = np.r_[(self.template_pdf)[0], self.template_pdf, (self.template_pdf)[-1]]\n",
    "        h_counts = hl.hist(xs, weights=ws, bins=30)   #Evaluate accuracy of this spline especially at poles\n",
    "        h = h_counts.normalize(density=True) / (2*np.pi)\n",
    "        hrange = h.range[0]\n",
    "        \n",
    "        skw.setdefault('s', 0)\n",
    "        skw.setdefault('k', 2)\n",
    "        skw.setdefault('log', True)\n",
    "        s_hl = h.spline_fit(**skw)\n",
    "        \n",
    "        self.signal_acc_spline = s_hl.spline\n",
    "        '''\n",
    "        \n",
    "        print('Using csky to obtain acceptance spline...')\n",
    "        a = cy.utils.Arrays(init=self.sig_evs, convert=True)\n",
    "        spl = cy.pdf.SinDecAccParameterization(a).s\n",
    "        print('--> Acceptance Spline Done.')\n",
    "        \n",
    "        self.signal_acc_spline = spl\n",
    "\n",
    "        return self.signal_acc_spline\n",
    "    \n",
    "    def get_acc_from_spline(self, sindec, acc='signal'):\n",
    "        \"\"\"\n",
    "        Used spline to get acceptance at a give sin(Dec).\n",
    "        \n",
    "        Args:\n",
    "            sindec: Sine of declination(s)\n",
    "            \n",
    "            acc: One of \"signal\" or \"bg\" for which acceptance spline to use. (Default: 'signal')\n",
    "            \n",
    "        Returns: acceptance(s) for provided sin(Dec).\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if acc == 'signal':\n",
    "            try:\n",
    "                out = np.exp(self.signal_acc_spline.ev(self.gamma, sindec))\n",
    "            except AttributeError:\n",
    "                print('Signal acceptance spline not yet created. Creating now... \\n')\n",
    "                self.create_signal_acc_spline()\n",
    "                out = np.exp(self.signal_acc_spline.ev(self.gamma, sindec))\n",
    "                \n",
    "            return out\n",
    "                \n",
    "        elif acc == 'bg':\n",
    "            try:\n",
    "                out = np.exp(self.bg_acc_spline(sindec))\n",
    "            except AttributeError:\n",
    "                print('Background acceptance spline not yet created. Creating now... \\n')\n",
    "                self.create_bg_acc_spline()\n",
    "                out = np.exp(self.bg_acc_spline(sindec))\n",
    "                \n",
    "            return out\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError('Argument spline must be one of [\"signal\", \"bg\"].')\n",
    "            \n",
    "    def create_template_pdf(self, smooth_sig):\n",
    "        \"\"\"\n",
    "        Applies detector acceptance to template and smooths, normalizes.\n",
    "        \n",
    "        Args:\n",
    "            smooth_sig: Sigma (in radians) for gaussian smoothing using healpy.smoothing(x, sigma=smooth_sig)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Applying detector acceptance to template...\")\n",
    "        #Make acceptance spline\n",
    "        self.create_signal_acc_spline()\n",
    "        #Apply spline\n",
    "        template_acc = self.template * self.get_acc_from_spline(np.sin(self.bin_decs), acc='signal') \n",
    "      \n",
    "        template = self.template.copy()\n",
    "\n",
    "        def smooth(temp, smooth_sig):\n",
    "            temp_pdf = temp / (np.sum(temp))\n",
    "            mask = (self.template > 0) & (temp_pdf <= 0)\n",
    "            temp_pdf[mask] = hp.UNSEEN\n",
    "            \n",
    "            #Smooth\n",
    "            #template_pdf = self.template.copy()\n",
    "            temp_pdf = hp.smoothing(temp_pdf, sigma=smooth_sig)\n",
    "            #Reset nonsensical values \n",
    "            temp_pdf[mask] = 0\n",
    "            temp_pdf[temp_pdf < 1e-12] = 1e-12\n",
    "            dec_mask = (self.bin_decs<=np.radians(self.max_dec_deg)) & (self.bin_decs>=np.radians(self.min_dec_deg))\n",
    "            #Re-normalize\n",
    "            temp_pdf = temp_pdf / ( np.sum(temp_pdf[dec_mask]) * hp.nside2pixarea(self.nside) )\n",
    "            \n",
    "            return temp_pdf\n",
    "        \n",
    "        self.template_smoothed = smooth(template, smooth_sig)\n",
    "        self.template_acc_smoothed = smooth(template_acc, smooth_sig)\n",
    "        \n",
    "        #This, self.template_pdf, is what gets used in defining N_on and N_off.\n",
    "        #The above, self.template_acc_smoothed, will always be used for injections. \n",
    "        self.template_pdf = self.template_acc_smoothed\n",
    "\n",
    "        print('--> Template PDF Done. \\n')\n",
    "        \n",
    "        return\n",
    "\n",
    "    def multinomial_TS(self, n_sig, n, p_s, p_b):\n",
    "        \"\"\"\n",
    "        This function is used to calculate the multinomial TS:\n",
    "        TS = 2 \\sum_i n_i \\ln\\left( \\frac{n_s}{N}\\left(\\frac{s_i}{b_i} - 1\\right) + 1 \\right)\n",
    "        \n",
    "        It is minimized for n_sig in the fitting functions.\n",
    "        \n",
    "        Args:\n",
    "            n_sig: number of (signal) events\n",
    "            \n",
    "            n: array of event counts in pixels (via healpy)\n",
    "            \n",
    "            p_s: array of pixel-wise signal probabilities using signal/template PDf\n",
    "            \n",
    "            p_b: array of pixel-wise background probabilities using background PDF\n",
    "            \n",
    "        Returns: TS as calculated in the above equation.\n",
    "        \n",
    "        \"\"\"\n",
    "                \n",
    "        TS = 2.0 * np.sum( n * np.log( (n_sig / np.sum(n)) * (p_s / p_b - 1.0) + 1.0 ) )\n",
    "        \n",
    "        return TS\n",
    "    \n",
    "#    def poisson_TS(self, n_sig, n, p_s, p_b):\n",
    "#        \"\"\"\n",
    "#        This function is used to calculate the poisson TS.\n",
    "#        \n",
    "#        It is minimized for n_sig in the fitting functions.\n",
    "#        \n",
    "#        Args:\n",
    "#            n_sig: number of (signal) events\n",
    "#            \n",
    "#            n: array of event counts in pixels (via healpy)\n",
    "#            \n",
    "#            p_s: array of pixel-wise signal probabilities using signal/template PDf\n",
    "#            \n",
    "#            p_b: array of pixel-wise background probabilities using background PDF\n",
    "#            \n",
    "#        Returns: TS as calculated in the above equation.\n",
    "#        \n",
    "#        \"\"\"\n",
    "#                \n",
    "#        TS = 2.0 * np.sum( (n_sig / np.sum(n)) * (p_b - p_s) + n * np.log( (n_sig / np.sum(n)) * (p_s / p_b - 1.0) + 1.0 ) )\n",
    "#        \n",
    "#       return TS\n",
    "    \n",
    "    def get_pdfs(self, verbose=None):\n",
    "        \"\"\"\n",
    "        Creates signal and background pdfs used in the test statistic calculation/minimization.\n",
    "        \n",
    "        `p_s` is the signal PDF; i.e., the template_pdf with pixels that do not pass the cutoff set to 0 and renormalized within dec bounds\n",
    "        \n",
    "        `p_b` is the background PDF; i.e., using the bg spline of 'off' bin counts and renormalized within dec bounds\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "        \n",
    "        if verbose:\n",
    "            print('Creating signal and background PDFs for TS calculations...')\n",
    "        \n",
    "        mask = (self.template_pdf > self.cutoff)\n",
    "        dec_mask = (self.bin_decs<=np.radians(self.max_dec_deg)) & (self.bin_decs>=np.radians(self.min_dec_deg))\n",
    "        \n",
    "        p_s = self.template_pdf.copy()\n",
    "        \n",
    "        #Any pixels that do not pass the cutoff are set to 0 signal probability\n",
    "        p_s[~mask] = 0.0\n",
    "        p_s /= np.sum(p_s[dec_mask]) * hp.nside2pixarea(self.nside)\n",
    "        \n",
    "        p_b = self.get_acc_from_spline(np.sin(self.bin_decs), acc='bg')\n",
    "        p_b /= np.sum(p_b[dec_mask]) * hp.nside2pixarea(self.nside)\n",
    "        \n",
    "        #ReNormalize (is this right?)  \n",
    "        sum_p = np.sum(p_s[dec_mask] + p_b[dec_mask])\n",
    "        p_s /= sum_p\n",
    "        p_b /= sum_p\n",
    "        \n",
    "        self.p_s = p_s\n",
    "        self.p_b = p_b\n",
    "        \n",
    "        if verbose:\n",
    "            print('--> PDFs Done.')\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def get_one_fit(self, n_sig=0, truth=False, seed=None, verbose=None):\n",
    "        \"\"\"\n",
    "        Obtains a single all-sky likelihood ratio.\n",
    "        \n",
    "        Args:\n",
    "            n_sig: number of (signal) events to inject (Default: 0). Only used if truth=False\n",
    "                    \n",
    "            truth: Whether to use true event locations (True), or scramble in right ascension (False)\n",
    "        \n",
    "            seed: integer, Seed for numpy.random.default_rng() used to scramble events and pick injection locations\n",
    "                  (Default: None, meaning unpredictable)\n",
    "                  \n",
    "            verbose: True to show more output (Defaults to class's initited value)\n",
    "            \n",
    "        Returns: dictionary containing all-sky llr, sinDec llrs, and sinDec acceptances\n",
    "        \n",
    "        \"\"\"\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "        \n",
    "        if truth:\n",
    "            self.counts = self.binned_data.copy()\n",
    "\n",
    "        else:\n",
    "            self.counts = self.scrambler(seed=seed)                \n",
    "            if n_sig != 0:\n",
    "                self.template_injector(n_sig=n_sig, seed=seed)\n",
    "                \n",
    "        dec_mask = (self.bin_decs<=np.radians(self.max_dec_deg)) & (self.bin_decs>=np.radians(self.min_dec_deg))\n",
    "\n",
    "        n = self.counts[dec_mask].copy()\n",
    "        p_s = self.p_s[dec_mask].copy()\n",
    "        p_b = self.p_b[dec_mask].copy()\n",
    "        \n",
    "        #Then, minimize...\n",
    "        def min_neg_TS(ns):\n",
    "            return -1.0 * self.multinomial_TS(ns, n, p_s, p_b)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Minimizing -TS...')\n",
    "        res = iminuit.minimize(min_neg_TS, 1, bounds=[(0,np.sum(n))])\n",
    "        #res = sp.optimize.minimize(min_neg_TS, 1, bounds=[(0,np.sum(n))])\n",
    "        \n",
    "        fit_ns = res.x\n",
    "        fit_TS = -1.0 * res.minuit.fval\n",
    "        #fit_TS = -1.0 * res.fun\n",
    "        \n",
    "        result = np.array([(seed, fit_ns, fit_TS)], dtype=[('seed', int),('ns', float),('ts', float)])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f' --> One All Sky Fit Done: ns={fit_ns}, TS={fit_TS}')\n",
    "            \n",
    "        print(res)\n",
    "        return result\n",
    "    \n",
    "    def get_many_fits(self, num, n_sig=0, seed=None, verbose=None):\n",
    "        \"\"\"\n",
    "        Obtains multiple best-fit ns and TS.\n",
    "        \n",
    "        Args:\n",
    "            num: integer, number of llrs to compute\n",
    "            \n",
    "            n_sig: number of (signal) events to inject (Default: 0)\n",
    "                                    \n",
    "            seed: integer, seed used to create multiple new seeds for scrambles (Default: None, unpredictable)\n",
    "            \n",
    "            verbose: True to show more output (Defaults to class's initited value)\n",
    "            \n",
    "        Returns: dictionary with {'n_sig': n_sig, 'results': structured array of (seed, ns, ts) }\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f'Calculating {num} TS with {n_sig} injected event(s)...')\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "            \n",
    "        results = np.array([],dtype=[('seed', int),('ns', float),('ts', float)])\n",
    "        \n",
    "        num = int(num)\n",
    "        if num < 1:\n",
    "            raise ValueError(f'num must be a positive integer, got: {num}')\n",
    "        elif num == 1:\n",
    "            results = np.append(results, self.get_one_fit(n_sig=n_sig, seed=seed, acc=acc, verbose=verbose))\n",
    "        else:\n",
    "            rng_seed = np.random.default_rng(seed)\n",
    "            for i in range(1, num+1):\n",
    "                new_seed = rng_seed.integers(int(1e9))\n",
    "\n",
    "                results = np.append(results, self.get_one_fit(n_sig=n_sig, seed=new_seed, verbose=verbose))\n",
    "                    \n",
    "        res_dict = {'n_inj': n_sig, 'results': results}\n",
    "        \n",
    "        print(f'--> {num} Fits Done!')\n",
    "        \n",
    "        return res_dict        \n",
    "         \n",
    "    def fit_TS_chi2(self, tss):\n",
    "        \"\"\"\n",
    "        Fit distribution of TSs > 0 with a chi-squared funtion.\n",
    "        \n",
    "        Args:\n",
    "            tss: array of TSs\n",
    "        \n",
    "        Returns: Chi2 degrees of freedom, location, scale parameters\n",
    "        \n",
    "        \"\"\"\n",
    "        self.eta = np.mean(tss>0)\n",
    "        self.df, self.loc, self.scale = sp.stats.chi2.fit(tss[tss>0], 1)     # 1 indicates starting guess for chi2 degrees of freedom\n",
    "        self.chi2_fit = sp.stats.chi2(self.df, self.loc, self.scale)\n",
    "        \n",
    "        print('Chi2 distribution fit to TS > 0 with:')\n",
    "        print(f'    DoF: {self.df}')\n",
    "        print(f'    loc: {self.loc}')\n",
    "        print(f'    scale: {self.scale}')\n",
    "        print(f'    eta: {self.eta}')\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def TS_to_p(self, ts, bg=None, use='fit', dof=1):\n",
    "        \"\"\"\n",
    "        Converts given TS to p-value using chosen method.\n",
    "        \n",
    "        Args:\n",
    "            ts: float or array of floats, TS to convert to p-value\n",
    "            \n",
    "            bg: None or array, background TSs (Default: None)\n",
    "            \n",
    "            use: string, which method/distribution to use.\n",
    "                 One of 'fit', 'chi2_dof', or 'hist'. If 'fit' and argument bg is not None, will fit a Chi2 distribution to\\\n",
    "                 the provided bg distribution. If 'chi2_dof', will use a Chi2 with provided dof and loc=0, scale=1. If \\\n",
    "                 'hist', will use the bg TSs themselves. (Default: 'fit')\n",
    "                 \n",
    "            dof: Number of degrees of freedom to use if use='chi2_ndof'\n",
    "            \n",
    "        Returns: p-value(s)\n",
    "                 \n",
    "        \"\"\"\n",
    "        if use not in ['fit', 'chi2_dof', 'hist']:\n",
    "            raise ValueError(f'Argument use must be one of \"fit\", \"chi2_dof\", or \"hist\", got \"{use}\"')\n",
    "            \n",
    "        if (use == 'chi2_ndof') or (bg is None):\n",
    "            #TS --> p using generic Chi2 function\n",
    "            #Necessary if no BG distribution is provided\n",
    "            \n",
    "            print(f'Calculating p-value(s) using a Chi2 Distribution with {dof} degrees of freedom...')\n",
    "            p = sp.stats.chi2.sf(ts, df=dof)\n",
    "            print(f'    p = {p}')\n",
    "            \n",
    "        elif use == 'fit':\n",
    "            #TS --> p using Chi2 fit\n",
    "            #Requires BG dist to be provided\n",
    "            \n",
    "            print(f'Calculating p-value(s) using a Chi2 Distribution fit to provided background...')\n",
    "            self.fit_TS_chi2(bg)\n",
    "            p = self.chi2_fit.sf(ts)\n",
    "            print(f'    p = {p}')\n",
    "            \n",
    "        elif use == 'hist':\n",
    "            #TS --> p using distribution directly\n",
    "            #Requires BG dist to be provided\n",
    "            \n",
    "            print(f'Calculating p-value(s) using background TSs distribution directly...')\n",
    "            p = np.array([np.mean(bg >= t) for t in ts])\n",
    "            print(f'    p = {p}')\n",
    "            \n",
    "        return p\n",
    "    \n",
    "    def create_bin_count_spline(self):\n",
    "        \"\"\"\n",
    "        Creates a 2d spline of bin counts vs bin sin(dec) for use in creating scrambles with self.scrambler\n",
    "        \n",
    "        \"\"\"\n",
    "        #Use only \"off\" pixels for generating \"scrambled\" pixels\n",
    "        mask = (self.template_pdf <= self.cutoff)\n",
    "        \n",
    "        sindec_bins = np.unique(np.concatenate([\n",
    "                     np.linspace(-1, -0.93, 4 + 1),\n",
    "                     np.linspace(-0.93, -0.3, 10 + 1),\n",
    "                     np.linspace(-0.3, 0.05, 9 + 1),\n",
    "                     np.linspace(0.05, 1, 18 + 1) ]) )\n",
    "        count_bins = np.linspace(0, np.quantile(self.binned_data, 0.99), 100)\n",
    "        h = hl.hist((self.binned_data[mask], np.sin(self.bin_decs[mask])), \n",
    "                    bins = (count_bins, sindec_bins))\n",
    "\n",
    "        skw = {}\n",
    "        skw.setdefault('s', 0)\n",
    "        skw.setdefault('kx', 2)\n",
    "        skw.setdefault('ky', 2)\n",
    "        s_hl = h.spline_fit(**skw)\n",
    "        \n",
    "        self.bin_count_spline = s_hl.spline\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def scrambler(self, seed=None, verbose=None):\n",
    "        \"\"\"\n",
    "        Gets a map of \"scrambled\" counts by sampling from self.bin_count_spline with given sindec\n",
    "        \n",
    "        Args:       \n",
    "            seed: integer, Seed for numpy.random.default_rng() used to scramble events and pick injection locations\n",
    "                  (Default: None, meaning unpredictable)\n",
    "        \n",
    "        \"\"\"\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Creating random scramble with seed {seed}...')\n",
    "            \n",
    "        if not hasattr(self, 'bin_count_spline'):\n",
    "            self.create_bin_count_spline()\n",
    "        \n",
    "        unique_decs = np.unique(self.bin_decs)\n",
    "        \n",
    "        rng_scramble = np.random.default_rng(seed=seed)\n",
    "        counts = np.zeros_like(self.binned_data)\n",
    "        for dec in unique_decs:\n",
    "            mask = (self.bin_decs == dec)\n",
    "            crange = np.arange(np.quantile(self.binned_data[mask], 0.1), np.quantile(self.binned_data[mask], 0.9)+1, 1)\n",
    "            weights = np.clip(self.bin_count_spline.ev(crange, np.sin(dec)), a_min=1e-12, a_max=None)\n",
    "            counts[mask] = rng_scramble.choice(crange, size=np.sum(mask), p=weights/np.sum(weights))\n",
    "            \n",
    "        #Adjust so sum(counts) ~= sum(binned_data)\n",
    "        counts = np.around(counts * np.sum(self.binned_data) / np.sum(counts))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'--> Scrambling Done. Scramble contains {np.sum(counts)} total counts.')\n",
    "            \n",
    "        return counts            \n",
    "    \n",
    "    def template_injector(self, n_sig, seed=None, verbose=None):\n",
    "        \"\"\"\n",
    "        Injects events based on template probabilities.\n",
    "        \n",
    "        Args:\n",
    "            n_sig: number of events to inject (with poisson fluctuations)\n",
    "            \n",
    "            seed: integer, Seed for numpy.random.default_rng() used to pick injection locations (Default: None, meaning unpredictable)\n",
    "            \n",
    "        \"\"\"\n",
    "        #NOTE: energy not yet implemented. Gamma is unused here!\n",
    "        if verbose is None:\n",
    "            verbose = self.verbose\n",
    "                           \n",
    "        rng_inj = np.random.default_rng(seed=seed)\n",
    "        poisson_n_sig = rng_inj.poisson(lam=n_sig)\n",
    "        \n",
    "        #Injection bins are choice of ON bins (defined by self.template_pdf > self.cutoff) within dec bounds\n",
    "        #The probability of choice within the ON bins is always including the acceptance, whether template_pdf does or not. \n",
    "        mask = (self.template_pdf > self.cutoff)\n",
    "        dec_mask = (self.bin_decs<=np.radians(self.max_dec_deg)) & (self.bin_decs>=np.radians(self.min_dec_deg))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Injecting {n_sig} events in \"On\" bins according to template+acceptance probabilities with poisson fluctuation ({poisson_n_sig})...')\n",
    "        \n",
    "        inj_choice = np.arange(hp.nside2npix(self.nside))[mask & dec_mask]\n",
    "        inj_probs = self.template_acc_smoothed[mask & dec_mask] / np.sum(self.template_acc_smoothed[mask & dec_mask])\n",
    "        self.inj_bins = rng_inj.choice(inj_choice, size=poisson_n_sig, p=inj_probs)\n",
    "\n",
    "        \n",
    "        #Get unique injection bins and times to inject in each bin\n",
    "        bin_nums, bin_injs = np.unique(self.inj_bins, return_counts=True)\n",
    "        \n",
    "        #Add injections to counts in respective bins\n",
    "        self.counts[bin_nums] += bin_injs\n",
    "        \n",
    "        if verbose:\n",
    "            print('--> Injections Done.')\n",
    "                \n",
    "        return          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64361874-e57b-4fc1-88b5-9339e9fccd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/level2/binned/Level2_2020.binned_data.npy'\n",
    "sig_path = 'data/level2/sim/npy/Level2_sim.npy'\n",
    "grl_path = 'GRL.npy'\n",
    "template_path = 'templates/Fermi-LAT_pi0_map.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711d6bb-9b26-44ce-8f95-9bd835ff78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_chilln = BinnedTemplateAllSky(data_path, sig_path, grl_path, is_binned=True, savedir='data/level2/binned', name='Fermi_pi0_allsky', \n",
    "                 template=template_path, gamma=2.7, cutoff=10**(-1.0), \n",
    "                 nside=128, min_dec_deg=-80, max_dec_deg=80, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f51609-ca4f-4007-8f2d-1b4e25ea6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = bin_chilln.get_one_fit(n_sig=1e7, truth=False, seed=12, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c8c05-75e7-449d-83ba-e3becc0857b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninj = np.array([1, 1e4, 1e5, 1e6, 1e7])\n",
    "nrec = np.array([71378, 81255, 171070, 1069075, 10061559])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bc595-2e6c-4160-b78b-09dc9fb1a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0,1e7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8864175-38e5-4653-a945-dfb15a6c8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (a0, a1) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, facecolor='w')\n",
    "\n",
    "a0.plot(ninj, nrec)\n",
    "a0.plot(xs, xs, linestyle='--', c='k')\n",
    "a0.loglog()\n",
    "a0.set_ylabel('Fit')\n",
    "a0.set_xlim(1,1e7)\n",
    "a0.set_ylim(1,1e7)\n",
    "\n",
    "a1.plot(ninj, nrec-ninj)\n",
    "a1.plot(xs, [70000, 70000], linestyle='--', c='k')\n",
    "a1.set_ylabel('Fit - Injected')\n",
    "a1.set_xlabel('Injected')\n",
    "a1.set_ylim(60000, 80000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d83ea2-503a-4f3e-ab3b-09018328a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_mask = (bin_chilln.bin_decs <= np.radians(bin_chilln.max_dec_deg)) & (bin_chilln.bin_decs >= np.radians(bin_chilln.min_dec_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7e740-8e6c-4e68-b92d-7e1805fbca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bin_chilln.inj_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3e9a1-82c8-4314-b63b-55e6cca13d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((bin_chilln.p_s + bin_chilln.p_b)[dec_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33699863-a51c-473a-9f43-e665fecb35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nss = np.logspace(0, 7.5, 500)\n",
    "tss = [bin_chilln.multinomial_TS(x, bin_chilln.counts[dec_mask], bin_chilln.p_s[dec_mask], bin_chilln.p_b[dec_mask]) for x in nss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef965c3-8fe5-4548-9f59-4adbfdb8a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='w')\n",
    "plt.plot(nss, tss)\n",
    "plt.scatter(10061559, 614638, marker='+', color='r', label='Best Fit')\n",
    "plt.ylabel('TS')\n",
    "plt.xlabel('ns')\n",
    "plt.legend()\n",
    "#plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc8f9f-fcb0-4cc1-9e71-5272769c5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/hp.nside2pixarea(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c4165-a3d7-446e-851c-89d34f40d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(bin_chilln.p_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b24f7-79ac-41fe-9ce4-4bdf91033c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bin_chilln.p_s[bin_chilln.template_pdf<.1], bins=20)\n",
    "#plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc02dc-dbcf-474c-8714-4b1c04ea810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='w')\n",
    "\n",
    "x = bin_chilln.template_pdf\n",
    "\n",
    "#dec_mask = (bin_chilln.bin_decs<=np.radians(bin_chilln.max_dec_deg)) & (bin_chilln.bin_decs>=np.radians(bin_chilln.min_dec_deg))\n",
    "#mask = (x < .1)\n",
    "#x[~dec_mask] = hp.UNSEEN\n",
    "\n",
    "hp.mollview(np.log10(x), unit='log10 (counts)', rot=(180,0,0), title='Signal Injection')#, cmap='nipy_spectral')#, min=-3, max=1) \n",
    "hp.graticule(30, color='w', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64728023-6610-4e96-9562-8c61410630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sin(np.unique(bin_chilln.bin_decs))\n",
    "plt.plot(x, bin_chilln.get_acc_from_spline(x, acc='bg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11884a-0572-4961-ae9a-03aceeb5db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and append bkg trials\n",
    "pfs = {}\n",
    "dists = {}\n",
    "cutoff = 0.1\n",
    "gamma = 2.7\n",
    "for where_acc in ['allsky']:\n",
    "\n",
    "    filelist = sorted(glob(f'/data/user/mcampana/analysis/binned_tracks/trials/bkg/{where_acc}/cutoff/{cutoff}/gamma/{gamma}/trials*.npy'))\n",
    "    bg_tss = np.array([])\n",
    "    c = 0\n",
    "    for f in filelist:\n",
    "        c += 1\n",
    "        arr = np.load(f, allow_pickle=True)\n",
    "        bg_tss = np.append(bg_tss, np.array(list(arr.item()['results']))['ts'])\n",
    "\n",
    "    print(f'Loaded {c} files of background trials.')\n",
    "\n",
    "    med_bg_ts = np.median(bg_tss)\n",
    "\n",
    "    #load and append sig trials\n",
    "    #nsigs = np.sort(np.array(os.listdir(f'/data/user/mcampana/analysis/binned_tracks/trials/sig/{where_acc}/nsig/'), dtype=int))\n",
    "    nsigs = np.array([10000, 15000, 20000, 25000, 50000, 100000])#, 250000, 500000, 750000])\n",
    "    sig_tss = {}\n",
    "    passing = {}\n",
    "    for nsig in nsigs:\n",
    "        filelist = sorted(glob(f'/data/user/mcampana/analysis/binned_tracks/trials/sig/{where_acc}/cutoff/{cutoff}/gamma/{gamma}/nsig/{nsig}/trials*.npy'))\n",
    "        tss = np.array([])\n",
    "        c = 0\n",
    "        for f in filelist:\n",
    "            c += 1\n",
    "            arr = np.load(f, allow_pickle=True)\n",
    "            tss = np.append(tss, np.array(list(arr.item()['results']))['ts'])\n",
    "\n",
    "        sig_tss[nsig] = tss\n",
    "\n",
    "        #passing fractions\n",
    "        passing[nsig] = np.mean(tss > med_bg_ts)\n",
    "        \n",
    "    sig_tss[0] = bg_tss\n",
    "    \n",
    "    passing[0] = .5\n",
    "    \n",
    "    pfs[where_acc] = passing\n",
    "    dists[where_acc] = sig_tss\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b05967-6238-4aa1-bd6f-3a6ff8602ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='w')\n",
    "bins = np.linspace(1.2,2,50)\n",
    "\n",
    "for where_acc in ['allsky']: #['bothAcc', 'tempAcc', 'combAcc', 'allsky']\n",
    "    for nsig in np.append(np.array([0]), nsigs[:-2]):\n",
    "        if nsig == 0:\n",
    "            plt.hist(np.log10(dists[where_acc][nsig]), label=nsig, histtype='step', linewidth=3, bins=bins)\n",
    "        else:        \n",
    "            plt.hist(np.log10(dists[where_acc][nsig]), label=nsig, bins=bins)\n",
    "\n",
    "    plt.vlines(np.log10(np.median(dists[where_acc][0])), 0, 1000, linestyle='--', color='k')\n",
    "               \n",
    "#plt.xlim(0, 600)\n",
    "plt.title(fr'TS Distributions ($\\gamma$={gamma})')\n",
    "plt.xlabel('log10 TS')\n",
    "plt.ylabel('Number of Trials')\n",
    "plt.legend(title=r'Injected Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e099692-c563-4f31-a3c5-938b9b379702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d, splrep, splev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4e918-a5b0-492b-9dd1-fa53db2860ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0,100000,500)\n",
    "ys = {}\n",
    "for where_acc in ['allsky']:\n",
    "    passing = pfs[where_acc]\n",
    "    #f = interp1d(list(passing.keys()), list(passing.values()), kind='quadratic')\n",
    "    #ys[where_acc] = f(xs)\n",
    "    \n",
    "    dkeys = sorted(list(passing.keys()))\n",
    "    sorted_passing = {i: passing[i] for i in dkeys}\n",
    "    splr = splrep(list(sorted_passing.keys()), list(sorted_passing.values()), k=2, s=.0001)\n",
    "    ys[where_acc] = splev(xs, splr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ed26f-ad7f-4672-8993-d0c22b889b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'bothAcc': 'C0', 'tempAcc': 'C1', 'combAcc': 'C2', 'allsky': 'C3'}\n",
    "\n",
    "plt.figure(facecolor='w')\n",
    "for where_acc in ['allsky']:\n",
    "    passing = pfs[where_acc]\n",
    "    plt.scatter(sorted_passing.keys(), sorted_passing.values(), label=where_acc, color=colors[where_acc])\n",
    "    plt.plot(xs, ys[where_acc], color=colors[where_acc])\n",
    "\n",
    "plt.hlines(0.9, 0, 100000, linestyle='--', color='k')\n",
    "#plt.legend(title='')\n",
    "plt.title(fr'Passing Fraction ($\\gamma$={gamma})')\n",
    "plt.xlabel('Number of Injected Events')\n",
    "plt.ylabel('Fraction of Events > Median BG TS')\n",
    "plt.xlim(0,25000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01faeea-e4a0-4c79-a50e-3abb9ac6dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "splev(13000, splr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7396f-9da2-4305-a8c4-c3a5048a1bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
